{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3bb29b",
   "metadata": {},
   "source": [
    "## Data  class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152cd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "#this class is responsible for evenly distributing the poa_lab[POSITIVE & NEGATIVE]  \n",
    "class ReviewContainer: \n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return[x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return[x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        \n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c3207",
   "metadata": {},
   "source": [
    "## load  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e79802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia\\'s trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character\\'s voice on a strong subject and making it so that other peoples story may be heard through Mia\\'s.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/Books_small_10000.json'\n",
    "\n",
    "#take of the differece(reviews,review)\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall'])) #reviewText(text) and overallRating(score)\n",
    "        \n",
    "reviews[5].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def81ffe",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce8d8c07",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42,)\n",
    "\n",
    "#re-write the new sets into the  ReviewContainer class for evenly_distribution\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca0354cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "#arrays of text and sentiment for trainning and testing set called from the ReviewContainer class. \n",
    "#which are evenly_distributed\n",
    "\n",
    "\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7638a",
   "metadata": {},
   "source": [
    "### Bags of words Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd23e7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was our book club pick this month, so I chose to finish it.  I would not have gone much past half way otherwise.  It became so disjointed and boring that I scanned the last third just to get through to the end.  This author needed a good editor.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer() #TimeFrequency & InversedocumentFrequency\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x) ## because we dont want to fit another model so we just transform\n",
    "\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "\n",
    "#we are going to create models for our training set (train_x_vector, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8252d0",
   "metadata": {},
   "source": [
    " ## Classification\n",
    " \n",
    " ### Lear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79762436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    " \n",
    "\n",
    "clf_svm.predict(test_x_vectors[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd00a6",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c81b7399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fcbbc",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f1a8856",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "\n",
    "#A sparse matrix was passed, but dense data is required. Use .todense() to convert to a dense numpy array.\n",
    "train_x_vectors_dense = train_x_vectors.todense()\n",
    "test_x_vectors_dense= test_x_vectors.todense()\n",
    "\n",
    "\n",
    "clf_gnb.fit(train_x_vectors_dense, train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors_dense[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d94d2",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5aed6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    " \n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e0d75",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2366af",
   "metadata": {},
   "source": [
    "### mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c742614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6514423076923077\n",
      "0.6610576923076923\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.todense(), test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199759f2",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "193b16cf",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.80952381]\n",
      "[0.63942308 0.63942308]\n",
      "[0.65693431 0.66508314]\n",
      "[0.80291971 0.80760095]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#[y_true, x_predict,average=None, Pos_lables]\n",
    "#during the corse of improvement we evenlized the positive to negative only\n",
    "#therefore the f1_score returns only the [POSITIVE & NEGATIVE score]\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors),\n",
    "               average=None, \n",
    "               labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "\n",
    "print(f1_score(test_y,\n",
    "               clf_dec.predict(test_x_vectors), \n",
    "               average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors_dense),\n",
    "               average=None, \n",
    "               labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "\n",
    "print(f1_score(test_y,\n",
    "               clf_log.predict(test_x_vectors), \n",
    "               average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "\n",
    "#Results arrage according to pos_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ef2fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing \n",
    "test_set = ['very fun', \"bad book do not buy\", 'horible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107cc46",
   "metadata": {},
   "source": [
    "## Turning our Model (with grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83490a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']}])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [{'kernel': ['linear','rbf'], 'C': [1,4,8,16,32]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)\n",
    "\n",
    "#clf.predict(test_x_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1751359",
   "metadata": {},
   "source": [
    "### Check Performace of turn(clf) on mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c685093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8197115384615384\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_x_vectors, test_y))\n",
    "\n",
    "#it can be seen that there was an improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd330fc",
   "metadata": {},
   "source": [
    "### Check Performace of turn(clf) on f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a0a03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82269504 0.81662592]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, clf.predict(test_x_vectors),\n",
    "               average=None, \n",
    "               labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b4bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
